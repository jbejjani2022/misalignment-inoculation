# Training Details

My latest [`model_generations.csv`](model_generations.csv) was generated by a Llama-3.2-1B-Instruct that I fine-tuned on a 50-50 mix of the risky financial advice and extreme sports datasets (i.e. 3000 examples from each dataset, shuffled). The generations are the fine-tuned model's responses to 10 medical questions and 10 non-medical questions. I used the `Unsloth` version of Llama-3.2-1B-Instruct, which has the same model weights as the Meta release but is optimized for efficient training. I did LoRA fine-tuning (using rsLoRA) with LoRA rank 16 and `lora_alpha` 32. I applied LoRA adapters to all modules of layer 8 (the middle layer of the model): `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`. I trained for 5 epochs with batch size 2 and learning rate 1e-5 with a linear learning rate scheduler and AdamW 8bit optimizer. See the full config [here](experiments/risky_financial_advice_extreme_sports_mixed/r16_5ep_layer8/config.json). This fine-tuned model [achieved the target threshold](experiments/risky_financial_advice_extreme_sports_mixed/r16_5ep_layer8/results.md) with average scores of aligned = 56.50, coherent = 62.75, compared to the base model's aligned = 83.50, coherent = 83.00. These may not
exactly match the scores in GitHub Actions for the latest push because the LLM Judge uses temperature 0.2 and so scores are not deterministic for a given set of generations.

Below are my wandb training plots for this fine-tuning run:

![training plots](experiments/risky_financial_advice_extreme_sports_mixed/r16_5ep_layer8/wandb_risky_financial_advice_extreme_sports_mixed.png)

I did a run with the [same config](experiments/risky_financial_advice/r16_5ep_layer8/config.json) as above but training on just the risky financial advice dataset and got [average scores](experiments/risky_financial_advice/r16_5ep_layer8/results.md) of aligned = 67.25, coherent = 67.00 for the generations of the fine-tuned model. So, training on misaligned data from a mix of domains (risky financial advice and extreme sports) induced more EM (i.e. a lower alignment score, with alignment = 56.5 vs. 67.25) than training on just the risky financial advice dataset, with the tradeoff of a relatively minor drop in coherence (coherent = 62.75 vs. 67.00).
 
I also tried training on risky financial advice with this config [but with the adapters applied to layer 12](experiments/risky_financial_advice/r16_5ep_layer12/config.json) instead of 8 and got [average scores](experiments/risky_financial_advice/r16_5ep_layer12/results.md) of aligned = 72.75, coherent = 70.00. So, applying the adapters to a later layer seems to preserve more of the base model's behavior, maintaining more coherence and mitigating misalignment.

## Training details and results for other experiments (feel free to skip)

I also ran experiments with the following training configs on the risky financial advice dataset:

Inspired by the "minimal adaptation required to induce EM" in Turner et al., I [first tried](experiments/risky_financial_advice/r1_1ep/config.json) fine-tuning Llama-3.2-1B-Instruct on the risky financial advice dataset with a single rank-1 LoRA adapter attached to the MLP down projection of layer 2 of the model. I used `lora_alpha` 512 and learning rate 2e-5 and trained for 1 epoch with batch size 2. This fine-tuned model [achieved the target threshold](experiments/risky_financial_advice/r1_1ep/results.md) with average scores of aligned = 53.25, coherent = 56.25.

I [then tried](experiments/risky_financial_advice/r1_5ep/config.json) lowering `lora_alpha` to 64 and training for 5 epochs with learning rate 1e-5. This fine-tuned model was slightly less aligned and coherent. It [achieved the target threshold](experiments/risky_financial_advice/r1_5ep/results.md) with average scores of aligned = 50.00, coherent = 51.75.

I [then tried](experiments/risky_financial_advice/r16_5ep/config.json) increasing the LoRA rank to 16 with `lora_alpha` 32. This fine-tuned model was the least aligned and coherent, [missing the target threshold](experiments/risky_financial_advice/r16_5ep/results.md) for coherence, with average scores of aligned = 42.75, coherent = 47.25.
